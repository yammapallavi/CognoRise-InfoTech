# -*- coding: utf-8 -*-
"""Breast_Cancer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1H313sk6aNU9q7xBWp3_YbrKYYe2rynZp
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report,confusion_matrix,ConfusionMatrixDisplay

"""# New section

# New section
"""

df=pd.read_csv('/content/data.csv')
df

df.head()

df.tail()

df.columns

df.dtypes

df.info()

for i in df:
  a=df[i].value_counts()
  print(a)

df.drop(['id','Unnamed: 32'],axis=1,inplace=True)

df.isna().sum()

df.duplicated().sum()

df.describe()

df['diagnosis'].value_counts()

sns.countplot(x='diagnosis',data=df,hue='diagnosis',palette='ocean')
plt.title('Diagnosis',color='green')

df['diagnosis']=df['diagnosis'].map({'M':1,'B':0})
df['diagnosis']

plt.figure(figsize=(9,6))
sns.boxplot(x='radius_mean',data=df,orient='h',width=0.4,color='green')
plt.show()

q1=df.quantile(0.25)
q3=df.quantile(0.75)
iqr=q3-q1
threshold=1.5
df=df[~((df<(q1-threshold*iqr))|(df>(q3+threshold*iqr))).any(axis=1)]
df

df.corr()

plt.figure(figsize=(16,11))
corr=df.corr()
sns.heatmap(corr,cmap='inferno',linewidths=.6,annot=True,annot_kws={"fontsize":6})
plt.show()

df_data=df.copy()
x_data=df_data.drop(['diagnosis'],axis=1)
y_data=df['diagnosis']
from sklearn.feature_selection import f_classif
score=f_classif(x_data,y_data)
score

f_value=pd.Series(score[0],index=x_data.columns)
f_value.sort_values(ascending=False)

p_value=pd.Series(score[1],index=x_data.columns)
p_value.sort_values(ascending=False)

df.drop(['fractal_dimension_mean','fractal_dimension_se','smoothness_se','texture_se'],axis=1,inplace=True)
df

x=df.drop(['diagnosis'],axis=1).values
y=df['diagnosis'].values
y

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.30,random_state=42)
y_train

scaler=MinMaxScaler()
scaler.fit(x_train)
x_train=scaler.transform(x_train)
x_test=scaler.transform(x_test)

knn_ex=KNeighborsClassifier()
param={'n_neighbors':[3,5,7,9],'weights':['uniform','distance']}
gcv=GridSearchCV(knn_ex,param,cv=10,scoring='accuracy')
gcv.fit(x_train,y_train)
print(gcv.best_params_)

knn=KNeighborsClassifier(n_neighbors=5,weights='uniform')
knn.fit(x_train,y_train)
y_pred=knn.predict(x_test)
y_pred

matrix=confusion_matrix(y_test,y_pred)
matrix

score_acc=accuracy_score(y_test,y_pred)
score_acc

repo=classification_report(y_test,y_pred)
print(repo)

labels=[0,1]
cmd=ConfusionMatrixDisplay(matrix,display_labels=labels)
cmd.plot()

dtc=DecisionTreeClassifier(criterion='entropy')
rfc=RandomForestClassifier(n_estimators=100,criterion='entropy')
lr=LogisticRegression(solver='saga',penalty='l2')

lst=[dtc,rfc,lr]
for i in lst:
  print(i)
  i.fit(x_train,y_train)
  y_predict=i.predict(x_test)
  print(confusion_matrix(y_test,y_predict))
  print(accuracy_score(y_test,y_predict))
  print(classification_report(y_test,y_predict))